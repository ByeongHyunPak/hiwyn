{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists('/content/hiwyn'):\n",
    "  %rm -rf /content/hiwyn\n",
    "!git clone https://github.com/ByeongHyunPak/hiwyn.git\n",
    "%cd /content/hiwyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install ninja-build\n",
    "!ninja --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('/content/hiwyn/nvdiffrast'):\n",
    "  %rm -rf /content/hiwyn/nvdiffrast\n",
    "!git clone --recursive https://github.com/NVlabs/nvdiffrast\n",
    "%cd /content/hiwyn/nvdiffrast\n",
    "!pip install .\n",
    "%cd /content/hiwyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import nvdiffrast.torch as dr\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Image\n",
    "from torchvision.transforms import ToPILImage, ToTensor\n",
    "from einops import rearrange, reduce, repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_opengl = False # On T4 GPU, only False works, but rasterizer works much better if = True\n",
    "glctx = dr.RasterizeGLContext() if use_opengl else dr.RasterizeCudaContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multidiffusion import MultiDiffusion\n",
    "from utils import cond_noise_sampling, identity_latent_warping, compute_erp_up_noise_pred\n",
    "to_img = ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the source noise, channel = 3\n",
    "up_level = 3   # Upsampling level k\n",
    "batch_size = 1 # Batch size\n",
    "dim_channel = 3    # Channel dimension\n",
    "H = 64   # Original H\n",
    "W = 64   # Original W\n",
    "\n",
    "src_noise = torch.randn(batch_size,dim_channel,H,W)\n",
    "\n",
    "# Upscale to 512 x 512 and visualize, just for visualization purposes\n",
    "view_test_noise = F.interpolate(src_noise, size=(512,512), mode='nearest')\n",
    "to_img(view_test_noise[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate conditionally upsampled noise by k = up_level\n",
    "up_noise = cond_noise_sampling(src_noise, level=up_level)\n",
    "\n",
    "\n",
    "# Visualize upsampled noise\n",
    "test_upsampled_noise_vis = F.interpolate(up_noise, size=(512,512), mode='nearest')\n",
    "to_img(test_upsampled_noise_vis[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_noise = identity_latent_warping(up_noise, (H, W), glctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_vis_fast = F.interpolate(tgt_noise, size=(512,512), mode='nearest')\n",
    "to_img(up_vis_fast[0])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
